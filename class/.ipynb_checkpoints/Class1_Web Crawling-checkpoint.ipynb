{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 웹 크롤링\n",
    "\n",
    "웹 상에 있는 정보들을 보다 빠르고 효율적으로 수집하는 방법이다. \n",
    "\n",
    "**[웹 크롤러 구조]**\n",
    "![Alt Text](https://upload.wikimedia.org/wikipedia/commons/d/df/WebCrawlerArchitecture.svg)\n",
    "\n",
    "(설명 및 이미지 출처 : https://ko.wikipedia.org/wiki/%EC%9B%B9_%ED%81%AC%EB%A1%A4%EB%9F%AC)\n",
    "\n",
    "\n",
    "**[수업 목표]**<br>\n",
    "이번 수업을 통해서 웹의 구조를 이해하고 원하는 데이터를 **requests와 selenium 패키지**를 활용하여 크롤링을 하는 방법에 대해 배운 후에\n",
    "**task scheduler**를 이용하여 자동화하는 실습을 해볼 예정이다.\n",
    "\n",
    "\n",
    "**[수업 순서]**<br>\n",
    "1) HTML, XML, JSON 구조의 이해\n",
    "\n",
    "2) requests, BeautifulSoup 패키지의 이해 \n",
    "\n",
    "3) selenium 패키지의 이해\n",
    "\n",
    "4) 자동화 실습\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### 1) HTML, XML, JSON 구조의 이해 \n",
    "웹은 HTML이라는 언어로 이루어져 있다. HTML의 기본적인 구조는 아주 간단하며 웹 상의 페이지에서 F12를 누르면 어떻게 작성되어 있는지 확인할 수 있다.\n",
    "\n",
    "웹 상에 나타나는 데이터는 주로 HTML, JSON, XML의 형식을 가지며 작성 형식의 차이만 조금 있어 각각의 방식에 맞게 Parsing 하는 법(다른 형식으로 저장된 데이터를 원하는 형식으로 변환하는 것)을 배워야 한다.\n",
    "\n",
    "HTML 구조 간단 설명 : http://html5tutorial.github.io/docs/HTML_boilerplate.html<br>\n",
    "HTML vs XML : https://www.quora.com/What-is-the-difference-between-HTML-and-XML/answer/Abhishek-Jain-25?share=1&srid=XIgg\n",
    "\n",
    "먼저, 간단한 구조를 보기 위해 사이트에(http://quotes.toscrape.com/page/1) 접속해서 F12를 눌러보자.<br>\n",
    "아래 그림처럼 우측에 조그만 창이 뜨고 HTML 작성 내용이 표기되어 있을 것이다. 마우스 커서 모양 버튼을 클릭한 후에 웹 페이지 내에 커서를 올리면 어떤 형식으로 입력되어 있는 지 확인할 수 있다.\n",
    "\n",
    "![F12](../pictures/HTML.PNG)\n",
    "\n",
    "위 그림은 title인 *Quotes to Scrape* 에 대해 확인한 결과이고 *&lt;a&gt;,&lt;/a&gt;* 로 둘러쌓여있으며 , href은 *\"/\"*, style은 *\"text-decoration: none\"*, 들어갈 text는 *Quotes to Scrape*가 입력되어 있다. href, style 등이 HTML에서 나타내는 형식으로 사용된다는 점만 알면 될 듯하고 이것들이 우리에게 필요한 text(데이터)를 찾을 때 이정표 역할을 해준다는 점만 알면 될 듯하다. \n",
    "\n",
    "\n",
    "그럼 우측 상단의 DevTools에 *Quotes to Scrape*가 HTML 형식으로 나타나 있는 부분에 마우스 커서를 올린 후에 \n",
    "오른쪽 클릭→Copy→Copy XPath, Copy element 를 하여 메모장에 붙여넣고 형식을 보자. \n",
    "\n",
    "우리가 앞으로 웹 상의 데이터를 가져올 때 많이 볼 형식들이고 차차 익숙해질 것이므로 걱정 안 해도 된다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) requests, BeautifulSoup 패키지의 이해\n",
    "\n",
    "두번째로 위에서 배운 HTML 형식으로 작성되어 있는 웹 상의 데이터를 가져오는 방법을 배울 것이다. \n",
    "requests라는 python의 패키지를 활용할 것이며 매우 편리하게 데이터를 가져올 수 있다.\n",
    "\n",
    "먼저, 로그인이 필요하지 않다고 가정한 상태에서 사용 법에 대해 간략하게 설명하고 업무 상 로그인이 필요한 경우 내용을 추가할 예정이다.\n",
    "\n",
    "웹 페이지 내용을 불러오는 건 매우 간단하다. 아래 Python 코드를 참조하자 \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests                            # requests를 import한다.\n",
    "url = 'http://quotes.toscrape.com/page/1'  # url을 변수로 저장한다. \n",
    "request = requests.get(url)                # url에 해당되는 내용을 불러온다. \n",
    "request = request.text                     # 불러온 내용을 text화 시킨다.\n",
    "request"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "F12로 확인한 모든 내용이 들어있는 것을 확인할 수 있다. 앞에서 &lt;a&gt;,&lt;/a&gt;, href, style 등의 HTML내 형식을 이정표로 사용한다고 설명했다. text로 가져온 데이터를 보기 편리하고 문자에 쉽게 접근할 수 있도록 해줘야 하는데 이때 사용하는 것이 BeautifulSoup이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(request, 'lxml')\n",
    "soup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아까 본 title의 형식을 가져와서 이정표로 활용해보자. &lt;a&gt; href=\"/\" style=\"text-decoration: none\">Quotes to Scrape &lt;a&gt; <br>\n",
    "활용할 수 있어 보이는게 ① &lt;a&gt; ② href ③ style 이고 더 바깥까지 보면 + ④ &lt;h&gt; ⑤ &lt;div class = \"col-md-8\"&gt; 까지 고려할 수 있어 보인다.\n",
    "\n",
    "BeautifulSoup내 함수를 사용해서 복잡해보이는 HTML 형식에서 원하는 것들만 뽑아내보자.\n",
    "\n",
    "사용할 함수는 **find, findall**로 이 두 가지에 논리 조금만 더하면 너무 복잡하지 않은 원하는 text를 가져올 수 있다. \n",
    "\n",
    "일단 기본적인 반복 실습, 함수 사용 법 확인."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "soup.find(name = 'a')     # 첫 번째 a로 둘러쌓인 부분을 찾는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup.find_all(name = 'a') # 모든 a로 둘러쌓인 부분을 찾는다. (list 반환)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup.find(name = 'h1')    # 첫 번째 h1로 둘러쌓인 부분을 찾는다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup.find_all(name = 'h1')# 모든 h1로 둘러쌓인 부분을 찾는다. (list 반환) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup.find(attrs = {'class' : \"col-md-8\"}) # 첫 번째 class가 col-md-8인 부분을 찾는다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup.find_all(attrs = {'class' : \"col-md-8\"}) # 모든 class가 col-md-8인 부분을 찾는다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "추가적으로 함수로 가져온 내용에서 특정한 내용 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "content = soup.find(name = 'h1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'text-decoration: none'"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content.a['style']  # content 내 a로 둘러쌓인 부분 내에 style값을 찾는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Quotes to Scrape'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "content.a.text      # content 내 a로 둘러쌓인 부분의 text를 찾는다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "주로 많은 사이트들은 게시판 내에 반복적인 형태로 게시물이 올라오기 때문에 위 내용까지만 배우면 특정 사이트에 특정 게시판에 접속하여 내용을 불러오고 내가 원하는 내용만 python 코드로 작성하여 가져올 수 있다. \n",
    "\n",
    "추가적으로 이제 ***특정 내용만 가져오고 싶다.*** 라는 필요가 생길텐데 이건 정규식을 조금만 배우면 쉽게 가능하다.\n",
    "해당 내용도 위의 *requests의 로그인하기*와 마찬가지로 필요할 경우에 추가적으로 학습하도록 하겠다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### 부록. 정규식\n",
    "\n",
    "정규식은 하나의 문자에 관련된 언어이고 모든 프로그래밍 언어에서 통용된다. 정규식을 사용해서 문자열에서 원하는 형식의 값만 추출해낼 수 있고 \n",
    "이를 위해서는 기본적인 문법을 알아야 한다.<br>\n",
    "아래 가장 기본적으로 사용되는 문법에 대해서 설명해놓았으니 필요 시 참조하면 된다.<br>\n",
    "파이썬에서는 정규식을 re 패키지에서 사용할 수 있다.<br>\n",
    "(정규식 설명 : https://wikidocs.net/4308)\n",
    "\n",
    "\n",
    "|구분|정규식 기호| 의미                  | 예제  |대상 값 : abcc123  ABC   |\n",
    "|:---:| :---:|:---| :-- |\n",
    "|특정 문자|아무 입력 값| 입력한 값   | 정규식 : 'abc' |   매칭 값 : 'abc'\n",
    "|특정 문자|[ ] | [ ]에 속한 범위 내 문자 중 1개|  정규식 : '[abc]' | 매칭 값 : 'a','b','c','c'\n",
    "|문자 그룹| .  | 모든 문자             | 정규식 : '.' | 매칭 값 : 'a','b','c','c','1','2','3','' ','A','B','C'\n",
    "|문자 그룹| \\d | 숫자| 정규식 : '\\d'| 매칭 값 : '1','2','3'\n",
    "|문자 그룹| \\D | 숫자 아닌 것들 | 정규식 : '\\D' | 매칭 값 : 'a','b','c','c',' ','A','B','C\n",
    "|문자 그룹| \\s | whitespace(\\t, \\n, \\t 등| 정규식 : '\\s' | 매칭 값 : ' '\n",
    "|문자 그룹| \\S | whitespace 아닌 것들| 정규식 : '\\S' | 매칭 값 : 'a','b','c','c','1','2','3','A','B','C'\n",
    "|반복| +  | 반복 (최소 1번 이상)  | 정규식 : 'c+' | 매칭 값 : 'cc'\n",
    "|반복| *  | 반복 (0번 ~ 무한대)   | 정규식 : '\\d*' | 매칭 값 : '','','','','123','','','','','' \n",
    "|반복|{m, n} | 반복 (m 이상 n 이하)| 정규식 : '\\d{1,3}' | 매칭 값 : '123'\n",
    "|반복| ? | 있거나 없거나 (0, 1) | 정규식 : 'a?bc+' | 매칭 값 : 'abcc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow35]",
   "language": "python",
   "name": "conda-env-tensorflow35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
