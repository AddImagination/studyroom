{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) selenium 패키지의 이해\n",
    "\n",
    "지금까지 requests, BeautifulSoup 패키지를 활용하여 웹 상에 HTML 형식을 따라가서 특정 원하는 데이터를 추출하는 법을 배웠다.\n",
    "\n",
    "추가적으로 selenium 패키지를 활용하여 웹 상에서 로그인이 유지되어야 하며 requests로 접근이 어려운 경우(naver 카페 등)\n",
    "정보를 가져오는 방법을 배워보도록 하겠다.\n",
    "\n",
    "먼저, selenium을 설치하고 chrome driver를 다운받도록 하자\n",
    "\n",
    "- selenium 설치 : cmd창에 pip install selenium\n",
    "- chrome driver 다운로드 : https://chromedriver.storage.googleapis.com/index.html?path=2.30/\n",
    "\n",
    "selenium은 기본적으로 python을 통해서 웹 브라우저에 접속한다고 생각하면 되며 실행시키면 Chrome이 뜨는 것을 볼 수 있다.\n",
    "\n",
    "접속한 후에 마우스로 버튼을 클릭하듯이 짜놓은 코드를 따라 브라우저 내에서 이동하게 된다.\n",
    "\n",
    "이 때, 앞 서 requests를 학습하면서 배웠던 HTML 형식을 마찬가지로 이정표로 삼을 것이며 원하는 데이터가 있는 위치에 도달했을 경우에\n",
    "해당 소스를 BeautifulSoup으로 읽어서 원하는 데이터만 가져올 수 있다.\n",
    "\n",
    "*웹 브라우저가 실제로 작동하기 때문에 requests 패키지보다 느리므로 requests로 처리하기 어려운 것들에 대해서만 하면 되겠다.*\n",
    "\n",
    "아래에서 본격적으로 selenium을 학습해보도록 하자.\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 15,
>>>>>>> e1535046d631958a3f995300724b9e7294198c26
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('C:/Anaconda3/Lib/site-packages/selenium')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\python36.zip',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\DLLs',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\lib',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Sphinx-1.5.1-py3.6.egg',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\win32\\\\lib',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\Pythonwin',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\setuptools-27.2.0-py3.6.egg',\n",
       " 'C:\\\\ProgramData\\\\Anaconda3\\\\lib\\\\site-packages\\\\IPython\\\\extensions',\n",
       " 'C:\\\\Users\\\\hslee3\\\\.ipython',\n",
       " 'C:/Anaconda3/Lib/site-packages/selenium']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "driver = webdriver.Chrome('C:/Users/hslee3/Desktop/개인용/과외/수업자료/studyroom/chromedriver.exe') # chrome driver 실행\n",
    "driver.implicitly_wait(2) # driver가 켜지는 동안 2초간 강제적으로 기다린다"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 25,
=======
   "execution_count": 16,
>>>>>>> e1535046d631958a3f995300724b9e7294198c26
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "driver.get('https://nid.naver.com/nidlogin.login')  # naver 로그인 창에 접속한다aa"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 26,
=======
   "execution_count": 17,
>>>>>>> e1535046d631958a3f995300724b9e7294198c26
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver.find_element_by_name('id').send_keys('kymkh0902') # naver 로그인 창에 id를 입력한다. \n",
    "driver.find_element_by_name('pw').send_keys('Rnjsgnl2@') # naver 로그인 창에 pw를 입력한다. "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 27,
=======
   "execution_count": 18,
>>>>>>> e1535046d631958a3f995300724b9e7294198c26
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath('//*[@id=\"frmNIDLogin\"]/fieldset/input').click() # login 버튼을 찾아서 클릭한다. "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 28,
=======
   "execution_count": 19,
>>>>>>> e1535046d631958a3f995300724b9e7294198c26
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver.get('http://cafe.naver.com/mlmodel') # 스터디 카페에 접속한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "//*[@id=\"cafe-data\"]/div[1]/div/div/div/div/span/a/img"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 30,
=======
   "execution_count": 7,
>>>>>>> e1535046d631958a3f995300724b9e7294198c26
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver.switch_to_frame('cafe_main') # 카페 내 iframe에 접근한다"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "driver.find_element_by_xpath('//*[@id=\"cafe-data\"]/div[1]/div/div/div/div/span/a/img').click() # more 버튼을 찾아서 클릭한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
=======
   "execution_count": 8,
>>>>>>> e1535046d631958a3f995300724b9e7294198c26
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "html = driver.page_source # html source를 가져온다. "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
=======
   "execution_count": 10,
>>>>>>> e1535046d631958a3f995300724b9e7294198c26
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(html, 'lxml') # 가져온 source를 BeautifulSoup으로 보기 좋게 만든다."
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": 12,
>>>>>>> e1535046d631958a3f995300724b9e7294198c26
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 원하는 데이터(글 제목)를 가져온다.\n",
    "data = soup.find(attrs = {'class':'article-board m-tcol-c'}).find_all(name = 'span', attrs = {'class' : 'aaa'}) \n",
    "result = [] # 데이터를 넣기 위한 빈 list를 하나 만들어준다. "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
=======
   "execution_count": 13,
>>>>>>> e1535046d631958a3f995300724b9e7294198c26
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['7/22 회의록', 'Giggle-gram gif from  2d x 2', 'Assignment #1 tip', 'Apple Machine learning blog\\n[1]', '현재까지의 정산 내역 \\n\\n[2]', 'assignment #1 해야할 일과 발표자 선정\\n[1]', 'Berkeley AI Research (BAIR)', '7/15(토) 스터디 후기(개인적인)\\n[4]', 'Arxiv Sanity Preserver', '7/15 스터디 후기\\n\\n[1]', '2017.07.02 Google I/O 후기\\n\\n[1]', '7/8(토) 스터디 후기(개인 기록)\\n[3]', '7/08 스터디 후기', 'Tensorflow Object Detection API\\n\\n[1]', 'Keras를 이용한 Object detection with neural networks']\n"
     ]
    }
   ],
   "source": [
    "for i in data:\n",
    "    result.append(i.text.strip()) # 원하는 데이터를 result에 순차적으로 넣어준다. \n",
    "    \n",
    "print(result) # result 출력"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 21,
=======
   "execution_count": 14,
>>>>>>> e1535046d631958a3f995300724b9e7294198c26
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "driver.close() # driver 닫는다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Task Scheduler의 이해\n",
    "\n",
    "지금까지 Web Scraping에 필요한 세가지 패키지를 통해 인터넷 상에 나타나 있는 데이터를 가져오는 방법에 대해 학습하였다.<br>\n",
    "다음 단계로 이런 일련의 데이터를 가져오는 과정을 사람 손을 타지 않는 완전한 자동화에 대해 배워보겠다.<br>\n",
    "이는 Windows OS에 존재하는 Task Scheduler라는 프로그램을 통해서 **손쉽게** 구현이 가능하며 주기적인 업무에 대해서 적용할 경우 효율이 크게 향상시킬 수 있다는 장점이 있다.\n",
    "\n",
    "그럼 Windows 검색 창에 **작업 스케줄러** 를 치고 실행시키자. \n",
    "\n",
    "![작업 스케줄러](https://wikidocs.net/images/page/5857/r18.08.png)\n",
    "\n",
    "실행했을 때 아래와 같은 화면을 볼 수 있다.<br>\n",
    "![실행 화면](../pictures/taskschd_1.PNG) <br>\n",
    "새로운 작업을 만들어보자. 위 화면에서 기본 작업 만들기를 실행하고 원하는 이름을 입력한 후에 다음 단계로 넘어가자. <br>\n",
    "![실행 화면](../pictures/taskschd_2.PNG) <br>\n",
    "수정할 수 있으므로 매일로 지정하고 다음 단계로 넘어가자. <br>\n",
    "![실행 화면](../pictures/taskschd_3.PNG) <br>\n",
    "넘어가자. <br>\n",
    "![실행 화면](../pictures/taskschd_4.PNG) <br>\n",
    "자동화의 목적이 Python을 실행시킨 후 Script를 1개 돌리는 것이므로 프로그램 시작을 선택한 후 다음으로 넘어가자. <br>\n",
    "![실행 화면](../pictures/taskschd_5.PNG) <br>\n",
    "실행시킬 프로그램은 Anaconda 폴더 내의 pythonw.exe 파일이다. (python.exe의 경우 콘솔 창이 실행되어 번거롭다.)\n",
    "그리고 인수를 추가해야 하는데 우리가 실행할 Script의 경로를 입력해주면 된다. <br>\n",
    "![실행 화면](../pictures/taskschd_6.PNG) <br>\n",
    "다음과 같이 web scraper라는 이름의 작업 스케줄러가 생성된 것을 확인할 수 있다. <br>\n",
    "![실행 화면](../pictures/taskschd_7.PNG) <br>\n",
    "마우스 오른쪽 클릭을 해서 실행시켜보자. 잘 실행된다. 이제 시간을 원하는 시간, 주기를 설정해서 업무를 자동화하도록 하자.\n",
    "(참조 site : https://wikidocs.net/5857)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
